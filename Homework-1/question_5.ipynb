{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3af0f9-7af1-4167-a446-f8b860c42605",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1cf12-1431-4203-ac84-a669287c5bbb",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c90992d4-f008-44da-b8ad-3627f75eac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/wiki2.train.txt\", \"r\") as file:\n",
    "    wiki_train = file.read()\n",
    "\n",
    "with open(\"data/examples.txt\", \"r\") as file:\n",
    "    example_test = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2c0ab0-f3ae-4c52-a9a3-75b50ce59667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01. Best known for developing the theory of relativity, Einstein also made important contributions t'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 100 characters\n",
    "example_test[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc959416-aad6-4e95-b9b8-0c6add582e61",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862c4021-8d41-4e3e-ba89-dbab37d23832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from utils.tokenization import chunked_tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03b580a-cc8b-488e-abad-30f8ed31240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"xx_ent_wiki_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b6e753-be19-427f-978c-15acad0e4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_train = chunked_tokenization(wiki_train, nlp)\n",
    "spacy_test = chunked_tokenization(example_test, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9221d7d-208a-44a5-900c-ca050c8e0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "from utils.tokenization import chunked_tokenization_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62751b6e-6d85-48ab-a54f-1812748ffa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48060d5c-09a5-4bc5-89a5-f8f4e1fa01fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1134371 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "gpt2_train = chunked_tokenization_gpt2(wiki_train, gpt2_tokenizer)\n",
    "gpt2_test = chunked_tokenization_gpt2(example_test, gpt2_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d53e6d-e71d-43b0-897f-c1e41cdd46c2",
   "metadata": {},
   "source": [
    "## Testing LaPlace Smoothened Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa1674d-c6f1-421d-a1a2-072b56df7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ngrams.laplace_ngrams import (\n",
    "    calculate_laplace_perplexities,\n",
    "    test_laplace_ngram_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f06041-633f-4f71-9356-6569474d2448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 Perplexities:\n",
      "{'1-gram': 2154.4990254150816, '2-gram': 7662.707268043866, '3-gram': 455220.731698504, '7-gram': 2249736.3442193987}\n"
     ]
    }
   ],
   "source": [
    "gpt2_perplexities = calculate_laplace_perplexities(gpt2_train, gpt2_test)\n",
    "print(\"GPT-2 Perplexities:\")\n",
    "print(gpt2_perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "875ae399-a29a-4310-9007-b6479091c65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy Perplexities:\n",
      "{'1-gram': 2154.0385663529423, '2-gram': 5292.625690807777, '3-gram': 378472.2068505432, '7-gram': 2092276.7487780796}\n"
     ]
    }
   ],
   "source": [
    "spacy_perplexities = calculate_laplace_perplexities(spacy_train, spacy_test)\n",
    "print(\"SpaCy Perplexities:\")\n",
    "print(spacy_perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3b012-018a-4e0d-a8b4-6f456bdc8618",
   "metadata": {},
   "source": [
    "## Testing Fine-Tuned GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fcd9ad8-52cc-47d6-a1ca-e1a0e3eb0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a196c1bb-925e-4185-a0d2-62a9e704940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"models/gpt2/\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"models/gpt2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faa44eae-24fd-4540-acf0-7bc9be306c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4c725e-47e2-4439-871a-dfbaefb11622",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = model.config.n_positions - 1\n",
    "stride = 32\n",
    "n = 0\n",
    "total_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dcac54f-be9c-4dd7-942e-fabc29e6b51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 48.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(example_test), stride)):\n",
    "    encoded_chunk = tokenizer.encode(example_test[i : i + max_length], return_tensors=\"pt\")\n",
    "\n",
    "    encoded_chunk = encoded_chunk.to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(encoded_chunk, labels=encoded_chunk)\n",
    "        total_loss += outputs.loss.item()\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b556ae43-4aca-4a5a-b4bc-48f7f8ddb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_loss = total_loss / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e264b7e-1dfe-43e0-8847-5593ed6dfde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 44.567405700683594\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(torch.tensor(average_loss)).item()\n",
    "print(f\"Perplexity: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e287649-0c81-4206-b913-a090f4b2543f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
