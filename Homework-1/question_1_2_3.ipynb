{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b21d3fe-df17-44b9-a7f2-c6f9cf791b1b",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185504a-699c-4cc9-b136-7f2d56a45ef4",
   "metadata": {},
   "source": [
    "## Reading Wiki Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df107a-78f4-4357-9882-7c164bc76c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/wiki2.train.txt\", \"r\") as file:\n",
    "    wiki_train = file.read()\n",
    "\n",
    "with open(\"data/wiki2.test.txt\", \"r\") as file:\n",
    "    wiki_test = file.read()\n",
    "\n",
    "with open(\"data/wiki2.valid.txt\", \"r\") as file:\n",
    "    wiki_valid = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d32ad-bc64-4a62-9c17-2a118bf31966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 100 characters\n",
    "wiki_train[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de22b65-6b81-4a5e-b5b1-604aa59031a0",
   "metadata": {},
   "source": [
    "## Spacy Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f0fd67-193d-41a6-b402-1d60bd4df579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b849d-e9c5-438c-9d93-c215e8c3d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"xx_ent_wiki_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4807c7ca-c1bb-406f-9f39-7c197688c7b7",
   "metadata": {},
   "source": [
    "This model is a multi-language model trained on Wikipedia, supporting named entity recognition for multiple languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3c8e7-5607-43d3-8187-287ad3c372bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked_tokenization(text, tokenizer, chunk_size=1000000):\n",
    "    tokens = []\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        text_chunk = text[i : i + chunk_size]\n",
    "        tokens.extend([token.text for token in tokenizer(text_chunk)])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381ea70-b8b1-47c6-a1c0-e8ea883980f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_train = chunked_tokenization(wiki_train, nlp)\n",
    "spacy_test = chunked_tokenization(wiki_test, nlp)\n",
    "spacy_valid = chunked_tokenization(wiki_valid, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d5b11-d2a3-477d-a9ec-eafad21eeebc",
   "metadata": {},
   "source": [
    "Before and after tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb8f723-dc1b-467d-8eea-c7724d5e7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_train[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea87d7-daff-45f6-b7fa-7483541c1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_train[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc59ea-5084-4ce0-800d-5724feb04f2e",
   "metadata": {},
   "source": [
    "## Pre-trained `GPT2TokenizerFast`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9221d7d-208a-44a5-900c-ca050c8e0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62751b6e-6d85-48ab-a54f-1812748ffa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a19668-b26b-4a02-aac1-3c6ba5428bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked_tokenization_gpt2(text, tokenizer, chunk_size=5000000):\n",
    "    tokens = []\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        text_chunk = text[i : i + chunk_size]\n",
    "        tokens.extend(tokenizer.tokenize(text_chunk))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48060d5c-09a5-4bc5-89a5-f8f4e1fa01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_train = chunked_tokenization_gpt2(wiki_train, gpt2_tokenizer)\n",
    "gpt2_valid = chunked_tokenization_gpt2(wiki_valid, gpt2_tokenizer)\n",
    "gpt2_test = chunked_tokenization_gpt2(wiki_test, gpt2_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6af73-17a0-44c0-8857-896a291a4022",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_train[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915ec293-b987-473a-8de0-b23ed5981b8d",
   "metadata": {},
   "source": [
    "* `Ġ` indicates a space before the word in the original text (part of GPT-2's byte pair encoding to differentiate between words that start after a space and subwords that occur in the middle of words)\n",
    "* `Ċ` represents a newline character in the text.\n",
    "* Words like \"Valkyria\" and \"Chronicles\" are split into subwords or individual characters (`V`, `alky`, `ria`, `Chronicles`), which are common subword units in the tokenizer's vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7763c-6a18-4573-a8d6-1c6dcce4ce13",
   "metadata": {},
   "source": [
    "## Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d2a36-d2dc-46fd-9b02-be0ad41c0054",
   "metadata": {},
   "outputs": [],
   "source": [
    "untokenized_test = wiki_test[0:1000].split(\" \")[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2475e-f59e-4032-8815-4bbee71ecfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Untokenized':<30} | {'Spacy Tokens':<30} | {'GPT-2 Tokens':<30}\")\n",
    "print(f\"{'-'*30}-+-{'-'*30}-+-{'-'*30}\")\n",
    "\n",
    "for i in range(200):\n",
    "    untokenized = repr(untokenized_test[i]) if i < len(untokenized_test) else \"\"\n",
    "    spacy_token = repr(spacy_test[i]) if i < len(spacy_test) else \"\"\n",
    "    gpt2_token = repr(gpt2_test[i]) if i < len(gpt2_test) else \"\"\n",
    "\n",
    "    untokenized = untokenized.strip(\"'\\\"\")\n",
    "    spacy_token = spacy_token.strip(\"'\\\"\")\n",
    "    gpt2_token = gpt2_token.strip(\"'\\\"\")\n",
    "\n",
    "    print(f\"{untokenized:<30} | {spacy_token:<30} | {gpt2_token:<30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a80603-ab35-4f96-807b-5875dc86d256",
   "metadata": {},
   "source": [
    "Some key differences we can see:\n",
    "\n",
    "1. **Granularity**:\n",
    "    1. Spacy produces more word-like tokens, closely aligning with the actual words and punctuations in the text. This could be because Spacy is designed for tasks that require understanding the text at the word level, such as part-of-speech tagging, entity recognition, and dependency parsing.\n",
    "    2. GPT-2 breaks down the text into subword units, represented as byte-pair encodings. This method captures the internal structure of words, allowing the model to handle a wide range of vocabulary, including neologisms and morphologically rich languages, with a fixed-size vocabulary.\n",
    "2. **Special Characters and Whitespace**:\n",
    "    1. Spacy treats newlines, spaces, and punctuation marks as separate tokens, which can be useful for syntactic parsing and sentence boundary detection.\n",
    "    2. GPT-2 has special tokens like `Ġ` to indicate a new word segment following a space, and `Ċ` for newlines, which helps in retaining the textual structure without needing a large vocabulary for whitespace variations.\n",
    "3. **Unknown Tokens**:\n",
    "    1. Spacy uses `<unk>` to represent unknown or out-of-vocabulary (OOV) tokens, which it cannot parse into known word types.\n",
    "    2. GPT-2 rarely encounters OOV tokens due to its subword tokenization. This allows it to piece together unfamiliar terms from known subword components, which is why we see pieces like `Ġ<` and `unk`.\n",
    "4. **Purpose**:\n",
    "    1. Spacy is optimized for NLP tasks requiring understanding of word forms and syntactic structures in context, e.g., NER, part-of-speech tagging, and dependecy parsing.\n",
    "    2. GPT-2 is designed for language generation and comprehension tasks, where subword units allow for more flexible word representation. This allows it to handle a wide variety of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08cd0d-67d1-47fa-ac78-2379753b5401",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "## Testing Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76a3a5-ffad-4e44-91ca-5ed3a7b2ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0316544c-0373-4063-bbb2-50429eddcb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngram_tokens(tokens, n):\n",
    "    \"\"\"\n",
    "    Generate a Counter of n-gram tuples from a list of tokens.\n",
    "\n",
    "    Args:\n",
    "        tokens (list of str): The list of tokens from which to generate n-grams.\n",
    "        n (int): The number of tokens in each n-gram.\n",
    "\n",
    "    Returns:\n",
    "        Counter: A Counter object mapping each n-gram tuple to its frequency.\n",
    "    \"\"\"\n",
    "    return Counter([tuple(tokens[i : i + n]) for i in range(len(tokens) - n + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495c9ce-e84a-4436-8e72-f226239ea8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_model(train_tokens, n):\n",
    "    \"\"\"\n",
    "    Generate n-gram and (n-1)-gram models from training tokens.\n",
    "\n",
    "    Args:\n",
    "        train_tokens (list of str): The list of tokens to train the model.\n",
    "        n (int): The n-gram size.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two Counter objects for n-gram and (n-1)-gram counts.\n",
    "    \"\"\"\n",
    "    ngram_counts = generate_ngram_tokens(train_tokens, n)\n",
    "    n_minus_1_gram_counts = generate_ngram_tokens(train_tokens, n - 1)\n",
    "\n",
    "    return ngram_counts, n_minus_1_gram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ca1c9-b2f2-4fb3-ab94-30cb5f403480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ngram_model(test_tokens, ngram_counts, n_minus_1_gram_counts, n, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Calculate the perplexity of a test dataset using an n-gram model.\n",
    "\n",
    "    Args:\n",
    "        test_tokens (list of str): The list of tokens to test the model.\n",
    "        ngram_counts (Counter): The n-gram counts from the training data.\n",
    "        n_minus_1_gram_counts (Counter): The (n-1)-gram counts from the training data.\n",
    "        n (int): The n-gram size.\n",
    "        epsilon (float): A small value to prevent zero-error in probability calculation.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated perplexity score.\n",
    "    \"\"\"\n",
    "    log_likelihood = 0.0\n",
    "    N = 0  # total n-grams in the test data\n",
    "\n",
    "    for i in range(len(test_tokens) - n + 1):\n",
    "        test_ngram = tuple(test_tokens[i : i + n])\n",
    "        test_n_minus_1_gram = test_ngram[:-1]\n",
    "\n",
    "        # Calculate the probability of the n-gram\n",
    "        numerator = ngram_counts.get(test_ngram, 0) + epsilon\n",
    "        denominator = n_minus_1_gram_counts.get(test_n_minus_1_gram, 0) + (\n",
    "            epsilon * len(n_minus_1_gram_counts)\n",
    "        )\n",
    "        prob = numerator / denominator\n",
    "\n",
    "        # total log likelihood\n",
    "        log_likelihood += math.log(prob)\n",
    "\n",
    "        N += 1\n",
    "\n",
    "    # Calculate perplexity\n",
    "    perplexity = math.exp(-log_likelihood / N)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c0de57-8d3b-4e57-a87b-bc17e0ca15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_tokens = [\n",
    "    \"this\",\n",
    "    \"is\",\n",
    "    \"a\",\n",
    "    \"sample\",\n",
    "    \"text\",\n",
    "    \"this\",\n",
    "    \"is\",\n",
    "    \"another\",\n",
    "    \"example\",\n",
    "    \"text\",\n",
    "]\n",
    "# test also contains OOV\n",
    "sample_test_tokens = [\"this\", \"is\", \"a\", \"test\", \"text\"]\n",
    "n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505274b4-0a9c-4c2c-af14-fcb55f4195e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_bigram_counts, sample_bi_minus_1_gram_counts = get_ngram_model(\n",
    "    sample_train_tokens, n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f89cbb8-17ae-4b23-9280-7af7d07c20f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_bigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b383cc-5292-46df-a26f-26e927ace316",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_bi_minus_1_gram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf296c7-d3e6-4ed9-8cdd-8bdd07cd189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ngram_model(\n",
    "    sample_test_tokens, sample_bigram_counts, sample_bi_minus_1_gram_counts, n\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea498d-433b-40f0-ac1b-9c2ae9350367",
   "metadata": {},
   "source": [
    "Testing it on Dr Suess data from class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2864f5-979b-438b-ae88-8461bb98b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_suess_test = [\n",
    "    \"<s>\",\n",
    "    \"I\",\n",
    "    \"am\",\n",
    "    \"Sam\",\n",
    "    \"</s>\",\n",
    "    \"<s>\",\n",
    "    \"Sam\",\n",
    "    \"I\",\n",
    "    \"am\",\n",
    "    \"</s>\",\n",
    "    \"<s>\",\n",
    "    \"I\",\n",
    "    \"do\",\n",
    "    \"not\",\n",
    "    \"like\",\n",
    "    \"green\",\n",
    "    \"eggs\",\n",
    "    \"and\",\n",
    "    \"ham\",\n",
    "    \"</s>\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680d812-35cb-4adf-b3aa-c6f91e851976",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngram_model(dr_suess_test, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef95d01-fb90-4e14-8039-ad492cefd323",
   "metadata": {},
   "source": [
    "$P((<s>\\cap I)|<s>) = $\n",
    "\n",
    "```python\n",
    "('<s>'): 3\n",
    "('<s>', 'I'): 2\n",
    "```\n",
    "\n",
    "$2/3 \\approx 0.67$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11caac-9e57-4e77-bca6-7f2c64f6692f",
   "metadata": {},
   "source": [
    "## Training and Testing n-gram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70d31e-f09f-4fb4-839c-e5f3111392b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexities(train_data, test_data):\n",
    "    perplexities = {}\n",
    "    for n in [1, 2, 3, 7]:\n",
    "        ngram_counts, n_minus_1_gram_counts = get_ngram_model(train_data, n)\n",
    "        perplexity = test_ngram_model(test_data, ngram_counts, n_minus_1_gram_counts, n)\n",
    "        perplexities[f\"{n}-gram\"] = perplexity\n",
    "    return perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9905b-2883-43d6-a76b-852ccc9d6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPT-2 vocab size:\", len(set(gpt2_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88fe395-1e9e-4fc5-be13-bdd8ed04746d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt2_perplexities = calculate_perplexities(gpt2_train, gpt2_test)\n",
    "print(\"GPT-2 Perplexities:\")\n",
    "print(gpt2_perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea9e02-774d-4bc3-8a94-2d5834abb1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SpaCy vocab size:\", len(set(spacy_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c0a9c-b619-4831-ae8f-a92caf3698cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_perplexities = calculate_perplexities(spacy_train, spacy_test)\n",
    "print(\"SpaCy Perplexities:\")\n",
    "print(spacy_perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485de637-6c77-495b-961e-430ac3d8c04d",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "* SpaCy has a larger vocabulary size than GPT-2.\n",
    "    * This could be a reason for its higher perplexity, especially in higher n-grams.\n",
    "    * SpaCy may also have more unique tokens and hence higher perplexity, reflecting the model's struggle to predict less frequent or more diverse sequences of words.\n",
    "    * A larger vocabulary can lead to more sparse data distributions (especially in higher n-grams), making accurate predictions more difficult.\n",
    "* uni-gram:\n",
    "    * relatively low for both GPT-2 and SpaCy\n",
    "    * GPT-2 has a slightly higher perplexity\n",
    "    * both models have a good grasp of the single-word distribution in the Wiki-data corpus\n",
    "    * suggests that SpaCy's tokenization method results in a distribution of tokens that slightly better reflects the test corpus.\n",
    "* bi-gram:\n",
    "    * GPT-2 shows a much lower perplexity compared to SpaCy\n",
    "    * suggests that GPT-2's tokenization aligns better with common two-word sequences in the Wiki-data\n",
    "    * or GPT-2 is more effective at capturing the syntactic structure of the \"Wiki-data language\"\n",
    "* tri-gram and 7-gram:\n",
    "    * As we move to higher n-grams, the perplexity increases dramatically for both models, but it's much more pronounced for SpaCy.\n",
    "    * This increase is expected because higher n-grams are less frequent and the model has less information about these longer sequences in the training data, making accurate predictions harder.\n",
    "    * the significantly higher perplexity for SpaCy suggests that its tokenization method might result in less coherent or less frequent n-grams in the context of Wiki-data\n",
    "    * or SpaCy might be less effective at capturing the language's structure over longer sequences.\n",
    "* Overall, GPT-2 seems to be more effective at capturing the n-gram patterns of the Wiki-data corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d5050-eb30-4f0d-853c-b11f5fbf4c36",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "## Adding LaPlace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9beeb1-084d-4893-a980-29cb14aa3c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_laplace_ngram_model(test_tokens, ngram_counts, n_minus_1_gram_counts, n):\n",
    "    \"\"\"\n",
    "    Calculate the perplexity of a test dataset using an n-gram model with Laplace smoothing.\n",
    "\n",
    "    Args:\n",
    "        test_tokens (list of str): The list of tokens to test the model.\n",
    "        ngram_counts (Counter): The n-gram counts from the training data.\n",
    "        n_minus_1_gram_counts (Counter): The (n-1)-gram counts from the training data.\n",
    "        n (int): The n-gram size.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated perplexity score.\n",
    "    \"\"\"\n",
    "    log_likelihood = 0.0\n",
    "    N = 0  # total n-grams in the test data\n",
    "\n",
    "    # Vocabulary size for Laplace smoothing\n",
    "    V = len(n_minus_1_gram_counts)\n",
    "\n",
    "    for i in range(len(test_tokens) - n + 1):\n",
    "        test_ngram = tuple(test_tokens[i : i + n])\n",
    "        test_n_minus_1_gram = test_ngram[:-1]\n",
    "\n",
    "        # Calculate the probability of the n-gram\n",
    "        numerator = ngram_counts.get(test_ngram, 0) + 1\n",
    "        denominator = n_minus_1_gram_counts.get(test_n_minus_1_gram, 0) + V\n",
    "        prob = numerator / denominator\n",
    "\n",
    "        # total log likelihood\n",
    "        log_likelihood += math.log(prob)\n",
    "\n",
    "        N += 1\n",
    "\n",
    "    # Calculate perplexity\n",
    "    perplexity = math.exp(-log_likelihood / N)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af94944-f810-441f-abd6-e1fcc6426ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_laplace_perplexities(train_data, test_data):\n",
    "    perplexities = {}\n",
    "    for n in [1, 2, 3, 7]:\n",
    "        ngram_counts, n_minus_1_gram_counts = get_ngram_model(train_data, n)\n",
    "        perplexity = test_laplace_ngram_model(test_data, ngram_counts, n_minus_1_gram_counts, n)\n",
    "        perplexities[f\"{n}-gram\"] = perplexity\n",
    "    return perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab9e81-fb1a-46a3-97d8-611bc13f9ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_perplexities = calculate_laplace_perplexities(gpt2_train, gpt2_test)\n",
    "print(\"GPT-2 Perplexities:\")\n",
    "print(gpt2_perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa956035-4417-4480-8588-34d68434beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_perplexities = calculate_laplace_perplexities(spacy_train, spacy_test)\n",
    "print(\"SpaCy Perplexities:\")\n",
    "print(spacy_perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969ae716-327b-4597-88ab-a71f7f7624b3",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "* GPT-2 still performs consistently better than SpaCy after LaPlace smoothing.\n",
    "* uni-gram: perplexities improved for both models after smoothing\n",
    "* bi-gram:\n",
    "    * this worsened (i.e. increased for both models after smoothing)\n",
    "    * it indicates that the smoothing had a larger impact due to previously unseen bigrams now having a non-zero probability\n",
    "    * this increased is more pronounced for the GPT-2 model, possibly due to the smaller vocab size (10 percent points worser)\n",
    "* 3-gram and 7-gram:\n",
    "    * Substantially increased for both models.\n",
    "    * The increase is dramatic, indicating that with smoothing, the model is penalized more for unseen or rare n-grams, which are more common in higher-order n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2091f6f6-64f1-4bf2-8f2b-d61c7992e7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
